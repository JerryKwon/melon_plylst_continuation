{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MelonRec.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTe_ZDeIuZig",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c1a3b50-12e9-4c69-befc-4ab1b47c25f2"
      },
      "source": [
        "# colab drive 연동을 위한 code\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fE76LIH8wbR6"
      },
      "source": [
        "<div style=\"font-size:50px;font-weight:bold\" align=\"center\">사용 Model 도식</div>\n",
        "\n",
        "![model](https://user-images.githubusercontent.com/50820635/88534733-a9e58900-d043-11ea-821b-1166c64e2b42.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUSJbFi836Fv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bb9ccf8-9c6a-4c49-e9c8-04b18b2540bb"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import  collections \n",
        "\n",
        "project_path = \"/gdrive/MyDrive/colab/melon_playlist_continuation/\"\n",
        "default_file_path = os.path.join(project_path,\"data\")\n",
        "\n",
        "sys.path.append(default_file_path)\n",
        "!pip install fire\n",
        "\n",
        "# 대회에서 제공한 custom package\n",
        "from arena_util import load_json\n",
        "from evaluate import ArenaEvaluator"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fire\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/a7/0e22e70778aca01a52b9c899d9c145c6396d7b613719cd63db97ffa13f2f/fire-0.3.1.tar.gz (81kB)\n",
            "\r\u001b[K     |████                            | 10kB 26.6MB/s eta 0:00:01\r\u001b[K     |████████                        | 20kB 28.4MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 30kB 33.0MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 40kB 35.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 51kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 61kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 71kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 4.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire) (1.1.0)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.3.1-py2.py3-none-any.whl size=111005 sha256=7cfe62e0e60c6369267157bd1b6bc657062828f24013b296667679fd83c2f741\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/61/df/768b03527bf006b546dce284eb4249b185669e65afc5fbb2ac\n",
            "Successfully built fire\n",
            "Installing collected packages: fire\n",
            "Successfully installed fire-0.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7u9P4IdHctR"
      },
      "source": [
        "## data_util.py\n",
        "\n",
        "* tags_ids_convert: playlist에 있는 감정 Tag를 새로운 id를 부여한 tag2id, id2tag dictionary를 생성\n",
        "* save_freq_song_id_dict: 특정 빈도 이상의 노래만을 추출하여 새로운 id를 부여하는 song2id, id2song dictionary를 생성\n",
        "* genre_gn_all_preprocessing: 장르 정보 Dataframe을 대분류 / 소분류 장르 Dataframe으로 분리하여 생성\n",
        "* genre_DicGenerator: {대분류 장르: 대분류 id}, {상세 장르: 상세 id}, {song_id: 대분류 id}, {song_id, 소분류 id} dictionary를 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Z-2gykN6iwg"
      },
      "source": [
        "# Playlist에 있는 감정 Tag를 dictionary 형태로 새로운 id를 부여하며 변환하여 저장\n",
        "def tags_ids_convert(json_data, tag2id_filepath, id2tag_filepath):\n",
        "    playlist_df = pd.DataFrame(json_data)\n",
        "    tags_list = playlist_df['tags'].to_list()\n",
        "    _id = 0\n",
        "    tags_dict = dict()\n",
        "    ids_dict = dict()\n",
        "    tags_set = set()\n",
        "    for tags in tags_list:\n",
        "        for tag in tags:\n",
        "            if tag not in tags_set:\n",
        "                tags_set.add(tag)\n",
        "                tags_dict[tag] = _id\n",
        "                ids_dict[_id] = tag\n",
        "                _id += 1\n",
        "    with open(tag2id_filepath, 'wb') as f:\n",
        "        np.save(f, tags_dict)\n",
        "        print('{} is created'.format(tag2id_filepath))\n",
        "    with open(id2tag_filepath, 'wb') as f:\n",
        "        np.save(f, ids_dict)\n",
        "        print('{} is created'.format(id2tag_filepath))\n",
        "    return True\n",
        "\n",
        "# 특정 빈도수 이상의 노래를 선정 후 이를 새로운 song2id id2song dict로 재매핑\n",
        "def save_freq_song_id_dict(train, thr, default_file_path, model_postfix):\n",
        "    song_counter = collections.Counter()\n",
        "    for plylst in train:\n",
        "        song_counter.update(plylst['songs'])\n",
        "\n",
        "    selected_songs = []\n",
        "    song_counter = list(song_counter.items())\n",
        "    for k, v in song_counter:\n",
        "        if v > thr:\n",
        "            selected_songs.append(k)\n",
        "\n",
        "    # thr시 선정되는 곡의 수를 확인\n",
        "    print(f'{len(song_counter)} songs to {len(selected_songs)} songs')\n",
        "\n",
        "    freq_song2id = {song: _id for _id, song in enumerate(selected_songs)}\n",
        "    np.save(f'{default_file_path}/freq_song2id_thr{thr}_{model_postfix}', freq_song2id)\n",
        "    print(f'{default_file_path}/freq_song2id_thr{thr}_{model_postfix} is created')\n",
        "    id2freq_song = {v: k for k, v in freq_song2id.items()}\n",
        "    np.save(f'{default_file_path}/id2freq_song_thr{thr}_{model_postfix}', id2freq_song)\n",
        "    print(f'{default_file_path}/id2freq_song_thr{thr}_{model_postfix} is created')\n",
        "    \n",
        "\n",
        "def genre_gn_all_preprocessing(genre_gn_all):\n",
        "    # genre_gn_all: pd.DataFrame\n",
        "    ## 대분류 장르코드\n",
        "    # 장르코드 뒷자리 두 자리가 00인 코드를 필터링\n",
        "    gnr_code = genre_gn_all[genre_gn_all['gnr_code'].str[-2:] == '00']\n",
        "\n",
        "    ## 상세 장르코드\n",
        "    # 장르코드 뒷자리 두 자리가 00이 아닌 코드를 필터링\n",
        "    dtl_gnr_code = genre_gn_all[genre_gn_all['gnr_code'].str[-2:] != '00'].copy()\n",
        "    dtl_gnr_code.rename(columns={'gnr_code': 'dtl_gnr_code', 'gnr_name': 'dtl_gnr_name'}, inplace=True)\n",
        "\n",
        "    return gnr_code, dtl_gnr_code\n",
        "\n",
        "# {대분류 장르: 대분류 id}, {상세 장르: 상세 id}, {song_id: 대분류 id}, {song_id, 소분류 id}\n",
        "def genre_DicGenerator(gnr_code, dtl_gnr_code, song_meta):\n",
        "    ## gnr_dic (key: 대분류 장르 / value: 대분류 장르 id)\n",
        "    gnr_dic = {}\n",
        "    i = 0\n",
        "    for gnr in gnr_code['gnr_code']:\n",
        "        gnr_dic[gnr] = i\n",
        "        i += 1\n",
        "\n",
        "    ## dtl_dic (key: 상세 장르 / value: 상세 장르 id)\n",
        "    dtl_dic = {}\n",
        "    j = 0\n",
        "    for dtl in dtl_gnr_code['dtl_gnr_code']:\n",
        "        dtl_dic[dtl] = j\n",
        "        j += 1\n",
        "\n",
        "    ## song_gnr_dic (key: 곡 id / value: 해당 곡의 대분류 장르)\n",
        "    ## song_dtl_dic (key: 곡 id / value: 해당 곡의 상세 장르)\n",
        "    song_gnr_dic = {}\n",
        "    song_dtl_dic = {}\n",
        "\n",
        "    for s in song_meta:\n",
        "        song_gnr_dic[s['id']] = s['song_gn_gnr_basket']\n",
        "        song_dtl_dic[s['id']] = s['song_gn_dtl_gnr_basket']\n",
        "\n",
        "    return gnr_dic, dtl_dic, song_gnr_dic, song_dtl_dic"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8JLlpMxIbqZ"
      },
      "source": [
        "## MelonDataset.py\n",
        "AutoEncoder 및 Word2Vector 학습시 사용할 Pytorch Dataset을 생성하는 python script\n",
        "\n",
        "각 playlist에 대해 수록된 노래 및 태그를 전체 노래/태그 벡터에서 해당되는 값만 1로 변환한 벡터를 출력하고 이를 하나의 벡터로 concatenate\n",
        "\n",
        "* SongTagDataset: 매 스텝마다 playlist_id, [song_vector, tag_vector]를 반환하는 데이터셋\n",
        "* SongTagGenreDataset: 매 스텝마다 playlist_id, [song_vector, tag_vector], gnr_vector, detail_gnr_vector를 반환하는 데이터셋\n",
        "\n",
        "~~~\n",
        ".\n",
        "├── SongTagDataset\n",
        "│   ├── _song_ids2vec: 플레이리스트에 수록된 노래를 vector화 하는 함수\n",
        "│   ├── _tag_ids2vec: 플레이리스트에 있는 태그를 vector화 하는 함수\n",
        "├── SongTagGenreDataset\n",
        "│   ├── _init_song_meta: 대분류 / 소분류 장르에 대한 vector화 작업전 수반되는 dictonary 및 DataFrame 생성 함수\n",
        "│   ├── _song_ids2vec: 플레이리스트에 수록된 노래를 vector화 하는 함수\n",
        "│   ├── _tag_ids2vec: 플레이리스트에 있는 태그를 vector화 하는 함수\n",
        "│   ├── _get_gnr_vector: 플레이리스트의 노래들에 대해 대분류 장르를 각각 추출하여 vector화 하는 함수\n",
        "│   └── _get_dtl_gnr_vector: 플레이리스트의 노래들에 대해 소분류 장르를 각각 추출하여 vector화 하는 함수\n",
        ".\n",
        "~~~\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0_PrZro6Taw"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "from arena_util import load_json\n",
        "# from data_util import genre_gn_all_preprocessing, genre_DicGenerator\n",
        "import torch\n",
        "\n",
        "\n",
        "class SongTagDataset(Dataset):\n",
        "    def __init__(self, json_dataset, tag2id_file_path, prep_song2id_file_path):\n",
        "        self.train = json_dataset\n",
        "        self.tag2id = dict(np.load(tag2id_file_path, allow_pickle=True).item())\n",
        "        self.prep_song2id = dict(np.load(prep_song2id_file_path, allow_pickle=True).item())\n",
        "        self.num_songs = len(self.prep_song2id)\n",
        "        self.num_tags = len(self.tag2id)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.train)\n",
        "\n",
        "    # song_vec, tag_vec를 AE에 넣기 위해 하나의 vector로 concatenate\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        _id = self.train[idx]['id']\n",
        "        song_vector = self._song_ids2vec(self.train[idx]['songs'])\n",
        "        tag_vector = self._tag_ids2vec(self.train[idx]['tags'])\n",
        "        _input = torch.from_numpy(\n",
        "            np.concatenate([song_vector, tag_vector]).astype(np.float32))\n",
        "\n",
        "        return _id, _input\n",
        "\n",
        "    def _song_ids2vec(self, songs):\n",
        "        songs = [self.prep_song2id[song] for song in songs if song in self.prep_song2id.keys()]\n",
        "\n",
        "        songs = np.asarray(songs, dtype=np.int)\n",
        "        bin_vec = np.zeros(self.num_songs)\n",
        "        if len(songs) > 0:\n",
        "            bin_vec[songs] = 1\n",
        "        return np.array(bin_vec)\n",
        "\n",
        "    def _tag_ids2vec(self, tags):\n",
        "        tags = [self.tag2id[tag] for tag in tags if tag in self.tag2id.keys()]\n",
        "        tags = np.asarray(tags, dtype=np.int)\n",
        "        bin_vec = np.zeros(self.num_tags)\n",
        "        bin_vec[tags] = 1\n",
        "        return np.array(bin_vec)\n",
        "\n",
        "\n",
        "class SongTagGenreDataset(Dataset):\n",
        "    def __init__(self, json_dataset, tag2id_file_path, prep_song2id_file_path):\n",
        "        \n",
        "        project_path = \"/gdrive/MyDrive/colab/melon_playlist_continuation/\"\n",
        "        self.default_file_path = os.path.join(project_path,\"data\")\n",
        "\n",
        "        self.train = json_dataset\n",
        "        self.tag2id = dict(np.load(tag2id_file_path, allow_pickle=True).item())\n",
        "        self.prep_song2id = dict(np.load(prep_song2id_file_path, allow_pickle=True).item())\n",
        "        self.num_songs = len(self.prep_song2id)\n",
        "        self.num_tags = len(self.tag2id)\n",
        "        self._init_song_meta()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.train)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        _id = self.train[idx]['id']\n",
        "        song_vector = self._song_ids2vec(self.train[idx]['songs'])\n",
        "        tag_vector = self._tag_ids2vec(self.train[idx]['tags'])\n",
        "        gnr_vector = self._get_gnr_vector(self.train[idx]['songs'], self.gnr_code, self.gnr_dic, self.song_gnr_dic)\n",
        "        dtl_gnr_vector = self._get_dtl_gnr_vector(self.train[idx]['songs'], self.dtl_gnr_code, self.dtl_dic, self.song_dtl_dic)\n",
        "        _input = torch.from_numpy(np.concatenate([song_vector, tag_vector]).astype(np.float32))\n",
        "\n",
        "        return _id, _input, gnr_vector, dtl_gnr_vector\n",
        "\n",
        "    def _init_song_meta(self):\n",
        "        song_meta = load_json(os.path.join(self.default_file_path,'song_meta.json'))\n",
        "\n",
        "        genre_gn_all = pd.read_json(os.path.join(self.default_file_path,'genre_gn_all.json'), encoding='utf8', typ='series')\n",
        "        genre_gn_all = pd.DataFrame(genre_gn_all, columns=['gnr_name']).reset_index().rename(\n",
        "            columns={'index': 'gnr_code'})\n",
        "\n",
        "        self.gnr_code, self.dtl_gnr_code = genre_gn_all_preprocessing(genre_gn_all)\n",
        "        self.num_gnr = len(self.gnr_code)\n",
        "        self.num_dtl_gnr = len(self.dtl_gnr_code)\n",
        "        # {노래 - 대분류 장르}, {노래 - 소분류 장르} 데이터 생성\n",
        "        self.gnr_dic, self.dtl_dic, self.song_gnr_dic, self.song_dtl_dic = genre_DicGenerator(\n",
        "            self.gnr_code, self.dtl_gnr_code, song_meta)\n",
        "\n",
        "    # 노래를 등장 빈도로 구분한 song2id dict를 활용하여 id 값을 재부여\n",
        "    # & 23만곡 가운데에 등장한 노래에 대해서 1을 부여\n",
        "    def _song_ids2vec(self, songs):\n",
        "        songs = [self.prep_song2id[song] for song in songs if song in self.prep_song2id.keys()]\n",
        "\n",
        "        songs = np.asarray(songs, dtype=np.int)\n",
        "        bin_vec = np.zeros(self.num_songs)\n",
        "        # 등장한 노래에 대해 1값부여\n",
        "        if len(songs) > 0:\n",
        "            bin_vec[songs] = 1\n",
        "        return np.array(bin_vec)\n",
        "\n",
        "    def _tag_ids2vec(self, tags):\n",
        "        tags = [self.tag2id[tag] for tag in tags if tag in self.tag2id.keys()]\n",
        "        tags = np.asarray(tags, dtype=np.int)\n",
        "        bin_vec = np.zeros(self.num_tags)\n",
        "        bin_vec[tags] = 1\n",
        "        return np.array(bin_vec)\n",
        "\n",
        "    # 특정 플레이리스트에 있는 곡별로 대분류 장르가 포함되는 비율을 벡터로 표현\n",
        "    def _get_gnr_vector(self, songs, gnr_code, gnr_dic, song_gnr_dic):\n",
        "        # v_gnr (각 플레이리스트의 수록곡 장르 비율을 담은 30차원 vector)\n",
        "        v_gnr = np.zeros(len(gnr_code))\n",
        "        for t_s in songs:\n",
        "            for g in song_gnr_dic[t_s]:\n",
        "                if g in gnr_code['gnr_code'].values:\n",
        "                    v_gnr[gnr_dic[g]] += 1\n",
        "        if v_gnr.sum() > 0:\n",
        "            v_gnr = v_gnr / v_gnr.sum()\n",
        "        return v_gnr\n",
        "\n",
        "    def _get_dtl_gnr_vector(self, songs, dtl_gnr_code, dtl_dic, song_dtl_dic):\n",
        "        ## plylst_dtl (각 플레이리스트의 수록곡 상세 장르 비율을 담은 224차원 vector)\n",
        "        v_dtl = np.zeros(len(dtl_gnr_code))\n",
        "        for t_s in songs:\n",
        "            for g in song_dtl_dic[t_s]:\n",
        "                if g in dtl_gnr_code['dtl_gnr_code'].values:\n",
        "                    v_dtl[dtl_dic[g]] += 1\n",
        "        if v_dtl.sum() > 0:\n",
        "            v_dtl = v_dtl / v_dtl.sum()\n",
        "        return v_dtl"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgYVse99JTd3"
      },
      "source": [
        "## Models.py\n",
        "\n",
        "임베딩에 사용될 AutoEncode Model을 선언하는 python script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6zLKt1RBz6T"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class AutoEncoder(nn.Module):\n",
        "  def __init__(self, D_in, H, D_out, dropout):\n",
        "    super(AutoEncoder, self).__init__()\n",
        "    encoder_layer = nn.Linear(D_in, H, bias=True)\n",
        "    decoder_layer = nn.Linear(H, D_out, bias=True)\n",
        "\n",
        "    # 빠른 최적화 및 높은 성능을 위해 각 가중치들에 대해 정규화를 수행\n",
        "    torch.nn.init.xavier_uniform_(encoder_layer.weight)\n",
        "    torch.nn.init.xavier_uniform_(decoder_layer.weight)\n",
        "\n",
        "    self.encoder = nn.Sequential(\n",
        "                              nn.Dropout(dropout),\n",
        "                              encoder_layer,\n",
        "                              nn.BatchNorm1d(H),\n",
        "                              nn.LeakyReLU()\n",
        "                            )\n",
        "    \n",
        "    self.decoder = nn.Sequential(\n",
        "                              decoder_layer,\n",
        "                              nn.Sigmoid()\n",
        "                          )\n",
        "    \n",
        "  def forward(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciLXMfS8Mcln"
      },
      "source": [
        "## w2v.py\n",
        "임베딩시 사용하는 Word2Vec 학습 및 수행을 위한 python script\n",
        "\n",
        "각 playlist에 대해 수록된 노래 및 태그를 전체 노래/태그 벡터에서 해당되는 값만 1로 변환한 벡터를 출력하고 이를 하나의 벡터로 concatenate\n",
        "\n",
        "~~~\n",
        ".\n",
        "├── make_input4tokenizer\n",
        "│   ├── _wv_tags: 전체 플레이리스트의 tags list에서 각 tags를 하나의 string으로 변환하여 새로이 list에 append하여 반환\n",
        "│   ├── _wv_genre: 전체 장르 Dataframe에 대해서 세부 장르를 [전체장르, 세부장르] 형태로 list를 생성하여 반환\n",
        "├── train_tokenizer: w2v전 string token화 사용시 tokenizer 학습을 위해 사용하는 함수\n",
        "├── get_tokens_from_sentences: string으로 변환된 문장들을 하나의 element로 변환한 list를 element로 하는 list를 생성하여 바환\n",
        "├── get_tokens_from_sentence\n",
        "├── string2vec: w2v 모델 실행을 위한 class\n",
        "│   ├── set_model\n",
        "│   ├── save_embeddings\n",
        "│   ├── save_model\n",
        "│   ├── show_similar_words\n",
        "├── title_tokenizer: playlist title을 token화 하기 위한 class\n",
        "│   ├── make_input_file:\n",
        "│   ├── train_tokenizer:\n",
        "│   ├── get_tokens:\n",
        "├── train_tokenizer_w2v: tokenizer 및 w2v모델 학습 수행을 위한 함수\n",
        ".\n",
        "~~~\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUdLvISVKha2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a343fcb1-5540-491c-e70b-c290a71b4284"
      },
      "source": [
        "\n",
        "!pip install sentencepiece\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import torch\n",
        "import io\n",
        "import os\n",
        "import copy\n",
        "import random\n",
        "import math\n",
        "import datetime as dt\n",
        "import distutils.dir_util\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sentencepiece as spm\n",
        "\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "from gensim.models import Word2Vec as w2v\n",
        "from collections import Counter\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from torch import nn\n",
        "from arena_util import write_json, load_json\n",
        "\n",
        "vocab_size = 24000\n",
        "method = 'bpe'\n",
        "\n",
        "\n",
        "def load_json(fname):\n",
        "    with open(fname, encoding='utf8') as f:\n",
        "        json_obj = json.load(f)\n",
        "\n",
        "    return json_obj\n",
        "\n",
        "\n",
        "def make_input4tokenizer(train_file_path, genre_file_path, result_file_path, valid_file_path=None, test_file_path=None):\n",
        "    # 특정 playlist의 태그를 vector화\n",
        "    def _wv_tags(tags_list):\n",
        "        taS = []\n",
        "        for tags in tags_list:\n",
        "            taS.append(' '.join(tags))\n",
        "\n",
        "        return(taS)\n",
        "        \n",
        "    # 특정 playlist의 장르를 vector화\n",
        "    def _wv_genre(genre):\n",
        "        genre_dict = dict()\n",
        "        for code, value in genre:\n",
        "            code_num = int(code[2:])\n",
        "            # 상위 장르의 경우\n",
        "            if not code_num % 100:\n",
        "                cur_genre = value\n",
        "                genre_dict[cur_genre] = []\n",
        "            # 하위 장르의 경우\n",
        "            else:\n",
        "                value = ' '.join(value.split('/'))\n",
        "                genre_dict[cur_genre].append(value)\n",
        "        genre_sentences = []\n",
        "        for key in genre_dict:\n",
        "            sub_list = genre_dict[key]\n",
        "            key = ' '.join(key.split('/'))\n",
        "            # 상위장르 key의 value list가 0인 경우\n",
        "            if not len(sub_list):\n",
        "                continue\n",
        "            for sub in sub_list:\n",
        "                genre_sentences.append(key+' '+sub)\n",
        "        return genre_sentences\n",
        "\n",
        "    try:\n",
        "        plylsts = load_json(train_file_path)\n",
        "        if valid_file_path is not None:\n",
        "            val_plylsts = load_json(valid_file_path)\n",
        "            plylsts += val_plylsts\n",
        "        if test_file_path is not None:\n",
        "            test_plylsts = load_json(test_file_path)\n",
        "            plylsts += test_plylsts\n",
        "\n",
        "        genre_all = load_json(genre_file_path)\n",
        "        genre_all_lists = []\n",
        "        for code, gnr in genre_all.items():\n",
        "            if gnr != '세부장르전체':\n",
        "                genre_all_lists.append([code, gnr])\n",
        "        genre_all_lists = np.asarray(genre_all_lists)\n",
        "\n",
        "        sentences = []\n",
        "        for plylst in plylsts:\n",
        "            tiS = plylst['plylst_title']\n",
        "            taS = ' '.join(plylst['tags'])\n",
        "            upS = ' '.join(plylst['updt_date'][:7].split('-'))\n",
        "            sentences.append(' '.join([tiS, taS, upS]))\n",
        "\n",
        "        geS = _wv_genre(genre_all_lists)\n",
        "        # 각노래와 플레이리스트에 대해서 장르를 붙이는게 아니라 그냥 전체 장르 데이터를 붙여버림,,, ???\n",
        "        sentences = sentences + geS\n",
        "        with open(result_file_path, 'w', encoding='utf8') as f:\n",
        "            for sentence in sentences:\n",
        "                f.write(sentence+'\\n')\n",
        "    except Exception as e:\n",
        "        print(e.with_traceback())\n",
        "        return False\n",
        "    return sentences\n",
        "\n",
        "\n",
        "def train_tokenizer(input_file_path, model_file_path, vocab_size, model_type):\n",
        "    templates = ' --input={} \\\n",
        "        --pad_id=0 \\\n",
        "        --bos_id=1 \\\n",
        "        --eos_id=2 \\\n",
        "        --unk_id=3 \\\n",
        "        --model_prefix={} \\\n",
        "        --vocab_size={} \\\n",
        "        --character_coverage=1.0 \\\n",
        "        --model_type={}'\n",
        "\n",
        "    cmd = templates.format(input_file_path,\n",
        "                model_file_path,    # output model 이름\n",
        "                vocab_size,# 작을수록 문장을 잘게 쪼갬\n",
        "                model_type)# unigram (default), bpe, char\n",
        "\n",
        "    spm.SentencePieceTrainer.Train(cmd)\n",
        "    print(\"tokenizer {} is generated\".format(model_file_path))\n",
        "\n",
        "def get_tokens_from_sentences(sp, sentences):\n",
        "    tokenized_sentences = []\n",
        "    for sentence in sentences:\n",
        "        tokens = sp.EncodeAsPieces(sentence)\n",
        "        new_tokens = []\n",
        "        for token in tokens:\n",
        "            token = token.replace(\"▁\", \"\")\n",
        "            if len(token) > 1:\n",
        "                new_tokens.append(token)\n",
        "        if len(new_tokens) > 1:\n",
        "            tokenized_sentences.append(new_tokens)\n",
        "\n",
        "    return tokenized_sentences\n",
        "\n",
        "\n",
        "def get_tokens_from_sentence(sp, sentence):\n",
        "    new_tokens = []\n",
        "    tokens = sp.EncodeAsPieces(sentence)\n",
        "    for token in tokens:\n",
        "        token = token.replace(\"▁\", \"\")\n",
        "        if len(token) > 1:\n",
        "            new_tokens.append(token)\n",
        "    return new_tokens\n",
        "\n",
        "\n",
        "class string2vec():\n",
        "    def __init__(self, train_data, size=200, window=5, min_count=2, workers=8, sg=1, hs=1):\n",
        "        self.model = w2v(train_data, size=size, window=window, min_count=min_count, workers=workers, sg=sg, hs=hs)\n",
        "\n",
        "    def set_model(self, model_fn):\n",
        "        self.model = w2v.load(model_fn)\n",
        "\n",
        "    def save_embeddings(self, emb_fn):\n",
        "        word_vectors = self.model.wv\n",
        "\n",
        "        vocabs = []\n",
        "        vectors = []\n",
        "        for key in word_vectors.vocab:\n",
        "            vocabs.append(key)\n",
        "            vectors.append(word_vectors[key])\n",
        "\n",
        "        df = pd.DataFrame()\n",
        "        df['voca'] = vocabs\n",
        "        df['vector'] = vectors\n",
        "\n",
        "        df.to_csv(emb_fn,index=False)\n",
        "\n",
        "    def save_model(self, md_fn):\n",
        "        self.model.save(md_fn)\n",
        "        print(\"word embedding model {} is trained\".format(md_fn))\n",
        "\n",
        "    def show_similar_words(self,word, topn):\n",
        "        print(self.model.most_similar(positive=[word], topn=topn))\n",
        "\n",
        "\n",
        "class title_tokenizer():\n",
        "    def make_input_file(self, input_fn, sentences):\n",
        "        with open(input_fn, 'w', encoding='utf8') as f:\n",
        "            for sentence in sentences:\n",
        "                f.write(sentence + '\\n')\n",
        "\n",
        "    def train_tokenizer(self, input_fn, prefix, vocab_size, model_type):\n",
        "        templates = '--input={}         --pad_id=0         --bos_id=1         --eos_id=2         --unk_id=3         --model_prefix={}         --vocab_size={}         --character_coverage=1.0         --model_type={}'\n",
        "\n",
        "        print(input_fn)\n",
        "\n",
        "        cmd = templates.format(input_fn,\n",
        "                               prefix,  # output model 이름\n",
        "                               vocab_size,  # 작을수록 문장을 잘게 쪼갬\n",
        "                               model_type)  # unigram (default), bpe, char\n",
        "\n",
        "        spm.SentencePieceTrainer.Train(cmd)\n",
        "        print(\"tokenizer model {} is trained\".format(prefix + \".model\"))\n",
        "\n",
        "    def get_tokens(self, sp, sentences):\n",
        "        tokenized_sentences = []\n",
        "\n",
        "        for sentence in sentences:\n",
        "            tokens = sp.EncodeAsPieces(sentence)\n",
        "            new_tokens = []\n",
        "            for token in tokens:\n",
        "                token = token.replace(\"▁\", \"\")\n",
        "                if len(token) > 1:\n",
        "                    new_tokens.append(token)\n",
        "            if len(new_tokens) > 1:\n",
        "                tokenized_sentences.append(new_tokens)\n",
        "\n",
        "        return tokenized_sentences\n",
        "\n",
        "\n",
        "def train_tokenizer_w2v(_train_file_path, _val_file_path, _test_file_path, _genre_file_path, _tokenize_input_file_path,\n",
        "                        _submit_type):\n",
        "\n",
        "    sentences = make_input4tokenizer(_train_file_path, _genre_file_path, _tokenize_input_file_path, _val_file_path,\n",
        "                                     _test_file_path)\n",
        "\n",
        "    project_path = \"/gdrive/MyDrive/colab/melon_playlist_continuation/\"\n",
        "    default_file_path = os.path.join(project_path,\"data\")\n",
        "\n",
        "    if not sentences:\n",
        "        sys.exit(1)\n",
        "\n",
        "    tokenizer_name = default_file_path+'/models/tokenizer_{}_{}_{}'.format(method, vocab_size, _submit_type)\n",
        "    tokenizer_name_model = default_file_path+'/models/tokenizer_{}_{}_{}.model'.format(method, vocab_size, _submit_type)\n",
        "    print(\"start train_tokenizer...w.\")\n",
        "    train_tokenizer(_tokenize_input_file_path, tokenizer_name, vocab_size, method)\n",
        "    sp = spm.SentencePieceProcessor()\n",
        "    sp.Load(tokenizer_name_model)\n",
        "    tokenized_sentences = get_tokens_from_sentences(sp, sentences)\n",
        "\n",
        "    w2v_name = default_file_path+'/models/w2v_{}_{}_{}.model'.format(method, vocab_size, _submit_type)\n",
        "    print(\"start train_w2v....\")\n",
        "    model = string2vec(tokenized_sentences, size=200, window=5, min_count=1, workers=8, sg=1, hs=1)\n",
        "    model.save_model(w2v_name)\n",
        "\n",
        "    return tokenized_sentences"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 5.3MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gP7U-Vk395v3"
      },
      "source": [
        "## train.py\n",
        "\n",
        "~~~\n",
        ".\n",
        "├── train: AE 학습 수행을 위한 함수\n",
        "├── AE 및 w2v 학습 수행을 위한 코드\n",
        ".\n",
        "~~~"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNqHFbBy-_L5"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "def train(train_dataset, model_file_path, id2prep_song_file_path, id2tag_file_path, question_dataset, answer_file_path):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # 변환한 tag dict 및 노래 빈도수 dict load\n",
        "    id2tag_dict = dict(np.load(id2tag_file_path, allow_pickle=True).item())\n",
        "    id2prep_song_dict = dict(np.load(id2prep_song_file_path, allow_pickle=True).item())\n",
        "\n",
        "    # parameters\n",
        "    num_songs = train_dataset.num_songs\n",
        "    num_tags = train_dataset.num_tags\n",
        "\n",
        "    # hyper parameters\n",
        "    D_in = D_out = num_songs + num_tags\n",
        "\n",
        "    #local_val mode인 경우 중간 중간 결과 확인 => mode 2 => None\n",
        "    q_data_loader = None\n",
        "    check_every = 5\n",
        "    tmp_result_file_path = default_file_path+'/results/tmp_results.json'\n",
        "    evaluator = ArenaEvaluator()\n",
        "    # mode 2 => None\n",
        "    if question_dataset is not None:\n",
        "        q_data_loader = DataLoader(question_dataset, shuffle=True, batch_size=batch_size, num_workers=num_workers)\n",
        "\n",
        "    # Auto encoder 투입용 DataLoader\n",
        "    data_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size, num_workers=num_workers)\n",
        "\n",
        "    model = AutoEncoder(D_in, H, D_out, dropout=dropout).to(device)\n",
        "\n",
        "    parameters = model.parameters()\n",
        "    loss_func = nn.BCELoss()\n",
        "    optimizer = torch.optim.Adam(parameters, lr=learning_rate)\n",
        "\n",
        "\n",
        "    try:\n",
        "        model = torch.load(model_file_path)\n",
        "        print(\"\\n--------model restored--------\\n\")\n",
        "    except:\n",
        "        print(\"\\n--------model not restored--------\\n\")\n",
        "        pass\n",
        "\n",
        "    # temp_fn = 'arena_data/answers/temp.json'\n",
        "    temp_fn = os.path.join(default_file_path,\"answers\",\"temp.json\")\n",
        "    if os.path.exists(temp_fn):\n",
        "        os.remove(temp_fn)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print()\n",
        "        print('epoch: ', epoch)\n",
        "        running_loss = 0.0\n",
        "        for idx, (_id, _data) in enumerate(tqdm_notebook(data_loader, desc='training...')):\n",
        "            _data = _data.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(_data)\n",
        "            loss = loss_func(output, _data)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print('loss: %d %d%% %.4f' % (epoch, epoch / epochs * 100, running_loss))\n",
        "\n",
        "        torch.save(model, model_file_path)\n",
        "\n",
        "        if mode == 0:\n",
        "            if epoch % check_every == 0:\n",
        "                if os.path.exists(tmp_result_file_path):\n",
        "                    os.remove(tmp_result_file_path)\n",
        "                elements = []\n",
        "                for idx, (_id, _data) in enumerate(tqdm(q_data_loader, desc='testing...')):\n",
        "                    with torch.no_grad():\n",
        "                        _data = _data.to(device)\n",
        "                        output = model(_data)\n",
        "\n",
        "                        songs_input, tags_input = torch.split(_data, num_songs, dim=1)\n",
        "                        songs_output, tags_output = torch.split(output, num_songs, dim=1)\n",
        "\n",
        "                        songs_ids = binary_songs2ids(songs_input, songs_output, id2prep_song_dict)\n",
        "                        tag_ids = binary_tags2ids(tags_input, tags_output, id2tag_dict)\n",
        "\n",
        "                        _id = list(map(int, _id))\n",
        "                        for i in range(len(_id)):\n",
        "                            element = {'id': _id[i], 'songs': list(songs_ids[i]), 'tags': tag_ids[i]}\n",
        "                            elements.append(element)\n",
        "\n",
        "                write_json(elements, tmp_result_file_path)\n",
        "                evaluator.evaluate(answer_file_path, tmp_result_file_path)\n",
        "                os.remove(tmp_result_file_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIWeo7Ebuuj1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "1725c0f9-50a8-4bac-8c53-818723b62472"
      },
      "source": [
        "# dimension\n",
        "H=450\n",
        "epochs=2\n",
        "batch_size=256\n",
        "learning_rate=0.0005\n",
        "dropout=0.2\n",
        "num_workers=20\n",
        "freq_thr=2\n",
        "# parser.add_argument('-mode', type=int, help=\"local_val: 0, val: 1, test: 2\", default=2)\n",
        "mode = 2\n",
        "\n",
        "# mode에 따른 train dataset과 관련 데이터 로드\n",
        "question_data = None\n",
        "question_dataset = None\n",
        "answer_file_path = None\n",
        "\n",
        "if mode == 0: # split data에 대해서는 훈련 중간 중간 성능 확인을 위해서 question, answer 불러옴\n",
        "    default_file_path = 'arena_data/'\n",
        "    model_postfix = 'local_val'\n",
        "\n",
        "    train_file_path = f'{default_file_path}/orig/train.json'\n",
        "    question_file_path = f'{default_file_path}/questions/val.json'\n",
        "    answer_file_path = f'{default_file_path}/answers/val.json'\n",
        "\n",
        "    train_data = load_json(train_file_path)\n",
        "    question_data = load_json(question_file_path)\n",
        "\n",
        "elif mode == 1:\n",
        "    # default_file_path = 'res'\n",
        "    model_postfix = 'val'\n",
        "\n",
        "    train_file_path = f'{default_file_path}/train.json'\n",
        "    val_file_path = f'{default_file_path}/val.json'\n",
        "    train_data = load_json(train_file_path) + load_json(val_file_path)\n",
        "\n",
        "elif mode == 2:\n",
        "    # default_file_path = 'res'\n",
        "    model_postfix = 'test'\n",
        "\n",
        "    train_file_path = f'{default_file_path}/train.json'\n",
        "    val_file_path = f'{default_file_path}/val.json'\n",
        "    test_file_path = f'{default_file_path}/test.json'\n",
        "    train_data = load_json(train_file_path) + load_json(val_file_path) + load_json(test_file_path)\n",
        "\n",
        "else:\n",
        "    print('mode error! local_val: 0, val: 1, test: 2')\n",
        "    sys.exit(1)\n",
        "\n",
        "# Autoencoder의 input: song, tag binary vector의 concatenate, tags는 str이므로 id로 변형할 필요 있음\n",
        "tag2id_file_path = f'{default_file_path}/tag2id_{model_postfix}.npy'\n",
        "id2tag_file_path = f'{default_file_path}/id2tag_{model_postfix}.npy'\n",
        "# Song이 너무 많기 때문에 frequency에 기반하여 freq_thr번 이상 등장한 곡들만 남김, 남은 곡들에게 새로운 id 부여\n",
        "prep_song2id_file_path = f'{default_file_path}/freq_song2id_thr{freq_thr}_{model_postfix}.npy'\n",
        "id2prep_song_file_path = f'{default_file_path}/id2freq_song_thr{freq_thr}_{model_postfix}.npy'\n",
        "# 관련 데이터들이 없으면 default file path에 새로 만들음\n",
        "if not (os.path.exists(tag2id_file_path) & os.path.exists(id2tag_file_path)):\n",
        "    tags_ids_convert(train_data, tag2id_file_path, id2tag_file_path)\n",
        "\n",
        "if not (os.path.exists(prep_song2id_file_path) & os.path.exists(id2prep_song_file_path)):\n",
        "    save_freq_song_id_dict(train_data, freq_thr, default_file_path, model_postfix)\n",
        "\n",
        "train_dataset = SongTagDataset(train_data, tag2id_file_path, prep_song2id_file_path)\n",
        "if question_data is not None:\n",
        "    question_dataset = SongTagDataset(question_data, tag2id_file_path, prep_song2id_file_path)\n",
        "\n",
        "model_file_path = default_file_path+'/models/autoencoder_{}_{}_{}_{}_{}_{}.pkl'. \\\n",
        "    format(H, batch_size, learning_rate, dropout, freq_thr, model_postfix)\n",
        "\n",
        "# 전체 song에 대한 playlist의 존재여부 벡터와 전체 Tag에 대한 playlist 존재여부 벡터를 concat && 학습\n",
        "train(train_dataset, model_file_path, id2prep_song_file_path, id2tag_file_path, question_dataset, answer_file_path)\n",
        "\n",
        "# w2v 학습 시작\n",
        "vocab_size = 24000\n",
        "# About bite pair encoding\n",
        "# https://wikidocs.net/22592 \n",
        "method = 'bpe'\n",
        "if model_postfix == 'val':\n",
        "    default_file_path = 'res'\n",
        "    question_file_path = 'res/val.json'\n",
        "    train_file_path = 'res/train.json'\n",
        "elif model_postfix == 'test':\n",
        "    # default_file_path = 'res'\n",
        "    # project_path = \"/gdrive/My Drive/colab/melon_playlist_continuation/\"\n",
        "    # default_file_path = os.path.join(project_path,\"data\")\n",
        "    val_file_path = os.path.join(default_file_path,'val.json')\n",
        "    question_file_path = os.path.join(default_file_path,'test.json')\n",
        "    train_file_path = os.path.join(default_file_path, 'train.json')\n",
        "elif model_postfix == 'local_val':\n",
        "    default_file_path = 'arena_data'\n",
        "    train_file_path = f'{default_file_path}/orig/train.json'\n",
        "    question_file_path = f'{default_file_path}/questions/val.json'\n",
        "    default_file_path = f'{default_file_path}/orig'\n",
        "\n",
        "genre_file_path = os.path.join(default_file_path, 'genre_gn_all.json')\n",
        "\n",
        "tokenize_input_file_path = default_file_path+f'/models/tokenizer_input_{method}_{vocab_size}_{model_postfix}.txt'\n",
        "\n",
        "if model_postfix == 'local_val':\n",
        "    val_file_path = None\n",
        "    test_file_path = None\n",
        "    train = load_json(train_file_path)\n",
        "    question = load_json(question_file_path)\n",
        "elif model_postfix == 'val':\n",
        "    test_file_path = None\n",
        "    val_file_path = question_file_path\n",
        "    train = load_json(train_file_path)\n",
        "    question = load_json(question_file_path)\n",
        "elif model_postfix == 'test':\n",
        "    val_file_path = val_file_path\n",
        "    test_file_path = question_file_path\n",
        "    train = load_json(train_file_path)\n",
        "    val = load_json(val_file_path)\n",
        "    test = load_json(test_file_path)\n",
        "    train = train + val\n",
        "    question = test\n",
        "\n",
        "tokenized_sentences = train_tokenizer_w2v(train_file_path, val_file_path, test_file_path, genre_file_path, tokenize_input_file_path, model_postfix)\n",
        "\n",
        "print('train completed')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-d2127a1c1d08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;31m# 전체 song에 대한 playlist의 존재여부 벡터와 전체 Tag에 대한 playlist 존재여부 벡터를 concat && 학습\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2prep_song_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2tag_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;31m# w2v 학습 시작\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-fd27acf6e7f1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_dataset, model_file_path, id2prep_song_file_path, id2tag_file_path, question_dataset, answer_file_path)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mdata_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m     def register_backward_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcompute_should_use_set_data\u001b[0;34m(tensor, tensor_applied)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_compatible_shallow_copy_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m                 \u001b[0;31m# If the new tensor has compatible tensor type as the existing tensor,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m                 \u001b[0;31m# the current behavior is to change the tensor in-place using `.data =`,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbgpgrpRAlcg"
      },
      "source": [
        "## get_autoencoder_scores.py\n",
        "\n",
        "~~~\n",
        ".\n",
        "├── AE_get_plylsts_embeddings: 학습한 AE 모델을 활용하여 플레이리스트의 벡터들에 대해서 embedding을 실시하는 함수\n",
        "├── AE_save_scores: embedding된 벡터를 가지고 유사도 점수를 추출하는 함수\n",
        "├── get_autoencoder_scores: 위의 두 함수를 활용하는 함수\n",
        ".\n",
        "~~~\n",
        "\n",
        "autoencoder로 임베딩한 벡터 기준\n",
        "\n",
        "numpy형태로 저장되는 test_scores_bias_cos.npy, test_scores_bias_cos_gnr.npy 는 dictonary 형태로 저장되며, 형태는 아래와 같다.\n",
        "\n",
        "* key: valid dataset의 playlist_id\n",
        "* values: list([train dataset에서 가장 유사도가 높은 상위 1000개의 train playlist)id ],[train dataset에서 가장 유사도가 높은 상위 1000개의 유사도 점수])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QO6ofDKCb2i"
      },
      "source": [
        "import random\n",
        "import torch.nn as nn\n",
        "import sentencepiece as spm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "# from MelonDataset import SongTagDataset, SongTagGenreDataset\n",
        "# from data_util import *\n",
        "from arena_util import write_json, load_json\n",
        "from evaluate import ArenaEvaluator\n",
        "from collections import Counter, defaultdict\n",
        "# from Models import AutoEncoder\n",
        "\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "random.seed(777)\n",
        "np.random.seed(777)\n",
        "\n",
        "\n",
        "def AE_get_plylsts_embeddings(_model_file_path, _submit_type, genre=False):\n",
        "\n",
        "    project_path = \"/gdrive/MyDrive/colab/melon_playlist_continuation/\"\n",
        "    default_file_path = os.path.join(project_path,\"data\")\n",
        "\n",
        "    if _submit_type == 'val':\n",
        "        default_file_path = 'res'\n",
        "        question_file_path = 'res/val.json'\n",
        "        train_file_path = 'res/train.json'\n",
        "        val_file_path = 'res/val.json'\n",
        "        train_dataset = load_json(train_file_path)\n",
        "    elif _submit_type == 'test':\n",
        "        # default_file_path = 'res'\n",
        "        question_file_path = os.path.join(default_file_path,'test.json')\n",
        "        train_file_path = os.path.join(default_file_path,'train.json')\n",
        "        val_file_path = os.path.join(default_file_path,'val.json')\n",
        "        train_dataset = load_json(train_file_path) + load_json(val_file_path)\n",
        "    elif _submit_type == 'local_val':\n",
        "        default_file_path = 'arena_data'\n",
        "        train_file_path = f'{default_file_path}/orig/train.json'\n",
        "        question_file_path = f'{default_file_path}/questions/val.json'\n",
        "        default_file_path = f'{default_file_path}/orig'\n",
        "        train_dataset = load_json(train_file_path)\n",
        "\n",
        "    tag2id_file_path = f'{default_file_path}/tag2id_{_submit_type}.npy'\n",
        "    id2tag_file_path = f'{default_file_path}/id2tag_{_submit_type}.npy'\n",
        "    prep_song2id_file_path = f'{default_file_path}/freq_song2id_thr2_{_submit_type}.npy'\n",
        "    id2prep_song_file_path = f'{default_file_path}/id2freq_song_thr2_{_submit_type}.npy'\n",
        "\n",
        "    if genre:\n",
        "        train_dataset = SongTagGenreDataset(train_dataset, tag2id_file_path, prep_song2id_file_path)\n",
        "        question_dataset = SongTagGenreDataset(load_json(question_file_path), tag2id_file_path, prep_song2id_file_path)\n",
        "    else:\n",
        "        train_dataset = SongTagDataset(train_dataset, tag2id_file_path, prep_song2id_file_path)\n",
        "        question_dataset = SongTagDataset(load_json(question_file_path), tag2id_file_path, prep_song2id_file_path)\n",
        "\n",
        "    plylst_embed_weight = []\n",
        "    plylst_embed_bias = []\n",
        "\n",
        "    model_file_path = _model_file_path\n",
        "\n",
        "    model = torch.load(model_file_path)\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            if name == 'encoder.1.weight':\n",
        "                plylst_embed_weight = param.data\n",
        "            elif name == 'encoder.1.bias':\n",
        "                plylst_embed_bias = param.data\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, shuffle=True, batch_size=256, num_workers=4)\n",
        "    question_loader = DataLoader(question_dataset, shuffle=True, batch_size=256, num_workers=4)\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # AE로 학습한 모델을 evaluation / test를 위해 변환\n",
        "    plylst_emb_with_bias = dict()\n",
        "\n",
        "    # 대분류 / 소분류 장르 벡터를 AE로 변환한 vector와 concat\n",
        "    if genre:\n",
        "        for idx, (_id, _data, _dnr, _dtl_dnr) in enumerate(tqdm(train_loader, desc='get train vectors...')):\n",
        "            with torch.no_grad():\n",
        "                _data = _data.to(device)\n",
        "                #???????????? why??\n",
        "                output_with_bias = (torch.matmul(_data, plylst_embed_weight.T) + plylst_embed_bias).tolist()\n",
        "                output_with_bias = np.concatenate([output_with_bias, _dnr, _dtl_dnr], axis=1)\n",
        "\n",
        "                _id = list(map(int, _id))\n",
        "                for i in range(len(_id)):\n",
        "                    plylst_emb_with_bias[_id[i]] = output_with_bias[i]\n",
        "\n",
        "        for idx, (_id, _data, _dnr, _dtl_dnr) in enumerate(tqdm(question_loader, desc='get question vectors...')):\n",
        "            with torch.no_grad():\n",
        "                _data = _data.to(device)\n",
        "                output_with_bias = (torch.matmul(_data, plylst_embed_weight.T) + plylst_embed_bias).tolist()\n",
        "                output_with_bias = np.concatenate([output_with_bias, _dnr, _dtl_dnr], axis=1)\n",
        "\n",
        "                _id = list(map(int, _id))\n",
        "                for i in range(len(_id)):\n",
        "                    plylst_emb_with_bias[_id[i]] = output_with_bias[i]\n",
        "    # AE로 변환한 vector만.\n",
        "    else:\n",
        "        for idx, (_id, _data) in enumerate(tqdm(train_loader, desc='get train vectors...')):\n",
        "            with torch.no_grad():\n",
        "                _data = _data.to(device)\n",
        "                output_with_bias = (torch.matmul(_data, plylst_embed_weight.T) + plylst_embed_bias).tolist()\n",
        "\n",
        "                _id = list(map(int, _id))\n",
        "                for i in range(len(_id)):\n",
        "                    plylst_emb_with_bias[_id[i]] = output_with_bias[i]\n",
        "\n",
        "        for idx, (_id, _data) in enumerate(tqdm(question_loader, desc='get question vectors...')):\n",
        "            with torch.no_grad():\n",
        "                _data = _data.to(device)\n",
        "                output_with_bias = (torch.matmul(_data, plylst_embed_weight.T) + plylst_embed_bias).tolist()\n",
        "\n",
        "                _id = list(map(int, _id))\n",
        "                for i in range(len(_id)):\n",
        "                    plylst_emb_with_bias[_id[i]] = output_with_bias[i]\n",
        "\n",
        "    # 훈련셋과 테스트셋에 대한 벡터값 추출\n",
        "    return plylst_emb_with_bias\n",
        "\n",
        "\n",
        "def AE_save_scores(_autoencoder_embs, _score_type, _submit_type, genre=False):\n",
        "\n",
        "    project_path = \"/gdrive/MyDrive/colab/melon_playlist_continuation/\"\n",
        "    default_file_path = os.path.join(project_path,\"data\")\n",
        "\n",
        "    if _submit_type == 'val':\n",
        "        question_file_path = 'res/val.json'\n",
        "        train_file_path = 'res/train.json'\n",
        "        val_file_path = 'res/val.json'\n",
        "        train_dataset = load_json(train_file_path)\n",
        "    elif _submit_type == 'test':\n",
        "        question_file_path = os.path.join(default_file_path,'test.json')\n",
        "        train_file_path = os.path.join(default_file_path, 'train.json')\n",
        "        val_file_path = os.path.join(default_file_path, 'val.json')\n",
        "        train_dataset = load_json(train_file_path) + load_json(val_file_path)\n",
        "    elif _submit_type == 'local_val':\n",
        "        default_file_path = 'arena_data'\n",
        "        train_file_path = f'{default_file_path}/orig/train.json'\n",
        "        question_file_path = f'{default_file_path}/questions/val.json'\n",
        "        train_dataset = load_json(train_file_path)\n",
        "\n",
        "    _train = train_dataset\n",
        "    _val = load_json(question_file_path)\n",
        "\n",
        "    def pcc(_x, _y):\n",
        "        vx = _x - torch.mean(_x)\n",
        "        vy = _y - torch.mean(_y, axis=1).reshape(-1, 1)\n",
        "        return torch.sum((vx * vy), axis=1) / (\n",
        "                    torch.sqrt(torch.sum(vx ** 2)) * torch.sqrt(torch.sum((vy ** 2), axis=1)))\n",
        "\n",
        "    def euclidean(_x, _y):\n",
        "        return torch.sqrt(torch.sum((_y - _x) ** 2, axis=1))\n",
        "\n",
        "    # 합쳐진 emb를 playlist id로 구분\n",
        "    all_train_ids = [plylst['id'] for plylst in _train]\n",
        "    all_val_ids = [plylst['id'] for plylst in _val]\n",
        "\n",
        "    train_ids = []\n",
        "    train_embs = []\n",
        "    val_ids = []\n",
        "    val_embs = []\n",
        "\n",
        "    for plylst_id, emb in tqdm(_autoencoder_embs.items()):\n",
        "        if plylst_id in all_train_ids:\n",
        "            train_ids.append(plylst_id)\n",
        "            train_embs.append(emb)\n",
        "        elif plylst_id in all_val_ids:\n",
        "            val_ids.append(plylst_id)\n",
        "            val_embs.append(emb)\n",
        "\n",
        "    gpu = torch.device('cuda')\n",
        "    cos = nn.CosineSimilarity(dim=1)\n",
        "\n",
        "    train_tensor = torch.tensor(train_embs).to(gpu)\n",
        "    val_tensor = torch.tensor(val_embs).to(gpu)\n",
        "\n",
        "    # scores 와 sorted_id는 순서대로 기록\n",
        "    # simliarity 점수를 출력 (val 개체 대상 수 X train 개체 대상 수)\n",
        "    scores = torch.zeros([val_tensor.shape[0], train_tensor.shape[0]], dtype=torch.float64)\n",
        "    # simliarity 점수가 높은 순서를 기록\n",
        "    sorted_idx = torch.zeros([val_tensor.shape[0], train_tensor.shape[0]], dtype=torch.int32)\n",
        "\n",
        "    # 하나의 val_vector와 전체 train_tensor간의 cosine simillarity 계산\n",
        "    for idx, val_vector in enumerate(tqdm(val_tensor)):\n",
        "        if _score_type == 'pcc':\n",
        "            output = pcc(val_vector.reshape(1, -1), train_tensor)\n",
        "        elif _score_type == 'cos':\n",
        "            output = cos(val_vector.reshape(1, -1), train_tensor)\n",
        "        elif _score_type == 'euclidean':\n",
        "            output = euclidean(val_vector.reshape(1, -1), train_tensor)\n",
        "        # simliarity 값이 높은 index를 앞으로 정렬\n",
        "        index_sorted = torch.argsort(output, descending=True)\n",
        "        scores[idx] = output\n",
        "        sorted_idx[idx] = index_sorted\n",
        "\n",
        "    # val 대상 playlist_id를 key로 하여 \n",
        "    results = defaultdict(list)\n",
        "    for i, val_id in enumerate(tqdm(val_ids)):\n",
        "        # 가장 상관성이 높은 상위 1000개의 플레이리스트\n",
        "        for j, train_idx in enumerate(sorted_idx[i][:1000]):\n",
        "            # (상위 1000개의 유사한 playlist_id, 상위 1000개의 유사도 점수)\n",
        "            results[val_id].append((train_ids[train_idx], scores[i][train_idx].item()))\n",
        "    if genre:\n",
        "        if _submit_type == 'val':\n",
        "            np.save(default_file_path+f'/results/val_scores_bias_{_score_type}_gnr', results)\n",
        "        elif _submit_type == 'test':\n",
        "            np.save(default_file_path+f'/results/test_scores_bias_{_score_type}_gnr', results)\n",
        "        else:\n",
        "            np.save(default_file_path+f'/results/local_val_scores_bias_{_score_type}_gnr', results)\n",
        "    else:\n",
        "        if _submit_type == 'val':\n",
        "            np.save(default_file_path+f'/results/val_scores_bias_{_score_type}', results)\n",
        "        elif _submit_type == 'test':\n",
        "            np.save(default_file_path+f'/results/test_scores_bias_{_score_type}', results)\n",
        "        else:\n",
        "            np.save(default_file_path+f'/results/local_val_scores_bias_{_score_type}', results)\n",
        "\n",
        "\n",
        "def get_autoencoder_scores(model_file_path, submit_type):\n",
        "    print(\"get autoencoder's latent embeddings\")\n",
        "    plylst_emb_with_bias = AE_get_plylsts_embeddings(model_file_path, submit_type, False)\n",
        "\n",
        "    print(\"get autoencoder's latent embeddings (genre embeddings are concated)\")\n",
        "    plylst_emb_with_bias_gnr = AE_get_plylsts_embeddings(model_file_path, submit_type, True)\n",
        "\n",
        "    print(\"save cos-similarity scores between test embeddings\")\n",
        "    AE_save_scores(plylst_emb_with_bias, 'cos', submit_type, False)\n",
        "\n",
        "    print(\"save cos-similarity scores between (test + genre) embeddings and train embeddings\")\n",
        "    AE_save_scores(plylst_emb_with_bias_gnr, 'cos', submit_type, True)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkChbuieSfrt"
      },
      "source": [
        "## get_w2v_scores.py\n",
        "\n",
        "~~~\n",
        ".\n",
        "├── W2V_get_plylsts_embeddings: 학습한 w2v 모델을 활용하여 플레이리스트의 벡터들에 대해서 embedding을 실시하는 함수\n",
        "├── W2V_save_scores: embedding된 벡터를 가지고 유사도 점수를 추출하는 함수\n",
        "├── get_w2v_scores: 위의 두 함수를 활용하는 함수\n",
        ".\n",
        "~~~\n",
        "\n",
        "w2v 모델로 임베딩한 벡터 기준\n",
        "\n",
        "numpy형태로 저장되는 test_scores_bias_cos.npy, test_scores_bias_cos_gnr.npy 는 dictonary 형태로 저장되며, 형태는 아래와 같다.\n",
        "\n",
        "* key: valid dataset의 playlist_id\n",
        "* values: list([train dataset에서 가장 유사도가 높은 상위 1000개의 train playlist)id ],[train dataset에서 가장 유사도가 높은 상위 1000개의 유사도 점수])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsqY16snSSBL"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import torch\n",
        "import io\n",
        "import os\n",
        "import copy\n",
        "import random\n",
        "import math\n",
        "import datetime as dt\n",
        "import distutils.dir_util\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sentencepiece as spm\n",
        "\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "from gensim.models import Word2Vec as w2v\n",
        "from collections import Counter\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from torch import nn\n",
        "from arena_util import write_json, load_json\n",
        "# from w2v import title_tokenizer\n",
        "\n",
        "vocab_size = 24000\n",
        "method = 'bpe'\n",
        "\n",
        "# 학습시킨 W2V에 대해서 embedding하는 벡터를 가져오는 함수\n",
        "def W2V_get_plylsts_embeddings(_train, _question, _submit_type):\n",
        "\n",
        "    \n",
        "    project_path = \"/gdrive/MyDrive/colab/melon_playlist_continuation/\"\n",
        "    default_file_path = os.path.join(project_path,\"data\")\n",
        "\n",
        "    print('saving embeddings')\n",
        "\n",
        "    # toekenizer model\n",
        "    tokenizer_name = default_file_path+'/models/tokenizer_{}_{}_{}.model'.format(method, vocab_size, _submit_type)\n",
        "    sp = spm.SentencePieceProcessor()\n",
        "    sp.Load(tokenizer_name)\n",
        "    tt = title_tokenizer()\n",
        "\n",
        "    # w2v model\n",
        "    w2v_model_name = default_file_path+'/models/w2v_{}_{}_{}.model'.format(method, vocab_size, _submit_type)\n",
        "    w2v_model = w2v.load(w2v_model_name)\n",
        "\n",
        "    # train plylsts to vectors\n",
        "    t_plylst_title_tag_emb = {}  # plylst_id - vector dictionary\n",
        "    for plylst in tqdm(_train):\n",
        "        p_id = plylst['id']\n",
        "        p_title = plylst['plylst_title']\n",
        "        p_title_tokens = tt.get_tokens(sp, [p_title])\n",
        "        if len(p_title_tokens):\n",
        "          # ?????\n",
        "            p_title_tokens = p_title_tokens[0]\n",
        "        else:\n",
        "            p_title_tokens = []\n",
        "        p_tags = plylst['tags']\n",
        "        p_times = plylst['updt_date'][:7].split('-')\n",
        "        p_words = p_title_tokens + p_tags + p_times\n",
        "        word_embs = []\n",
        "        for p_word in p_words:\n",
        "            try:\n",
        "                word_embs.append(w2v_model.wv[p_word])\n",
        "            except KeyError:\n",
        "                pass\n",
        "        if len(word_embs):\n",
        "            p_emb = np.average(word_embs, axis=0).tolist()\n",
        "        else:\n",
        "            p_emb = np.zeros(200).tolist()\n",
        "\n",
        "        t_plylst_title_tag_emb[p_id] = p_emb\n",
        "\n",
        "    # val plylsts to vectors\n",
        "    for plylst in tqdm(_question):\n",
        "        p_id = plylst['id']\n",
        "        p_title = plylst['plylst_title']\n",
        "        p_title_tokens = tt.get_tokens(sp, [p_title])\n",
        "        p_songs = plylst['songs']\n",
        "        if len(p_title_tokens):\n",
        "            p_title_tokens = p_title_tokens[0]\n",
        "        else:\n",
        "            p_title_tokens = []\n",
        "        p_tags = plylst['tags']\n",
        "        p_times = plylst['updt_date'][:7].split('-')\n",
        "        p_words = p_title_tokens + p_tags + p_times\n",
        "        word_embs = []\n",
        "        for p_word in p_words:\n",
        "            try:\n",
        "                word_embs.append(w2v_model.wv[p_word])\n",
        "            except KeyError:\n",
        "                pass\n",
        "        if len(word_embs):\n",
        "            p_emb = np.average(word_embs, axis=0).tolist()\n",
        "        else:\n",
        "            p_emb = np.zeros(200).tolist()\n",
        "        t_plylst_title_tag_emb[p_id] = p_emb\n",
        "\n",
        "    return t_plylst_title_tag_emb\n",
        "\n",
        "\n",
        "def W2V_save_scores(_train, _question, _autoencoder_embs, _score_type, _submit_type):\n",
        "\n",
        "    project_path = \"/gdrive/MyDrive/colab/melon_playlist_continuation/\"\n",
        "    default_file_path = os.path.join(project_path,\"data\")\n",
        "\n",
        "    print('saving scores...')\n",
        "\n",
        "    def pcc(_x, _y):\n",
        "        vx = _x - torch.mean(_x)\n",
        "        vy = _y - torch.mean(_y, axis=1).reshape(-1, 1)\n",
        "        return torch.sum((vx * vy), axis=1) / (\n",
        "                    torch.sqrt(torch.sum(vx ** 2)) * torch.sqrt(torch.sum((vy ** 2), axis=1)))\n",
        "\n",
        "    def euclidean(_x, _y):\n",
        "        return torch.sqrt(torch.sum((_y - _x) ** 2, axis=1))\n",
        "\n",
        "    all_train_ids = [plylst['id'] for plylst in _train]\n",
        "    all_val_ids = [plylst['id'] for plylst in _question]\n",
        "\n",
        "    train_ids = []\n",
        "    train_embs = []\n",
        "    val_ids = []\n",
        "    val_embs = []\n",
        "\n",
        "    for plylst_id, emb in tqdm(_autoencoder_embs.items()):\n",
        "        if plylst_id in all_train_ids:\n",
        "            train_ids.append(plylst_id)\n",
        "            train_embs.append(emb)\n",
        "        elif plylst_id in all_val_ids:\n",
        "            val_ids.append(plylst_id)\n",
        "            val_embs.append(emb)\n",
        "\n",
        "    gpu = torch.device('cuda')\n",
        "    cos = nn.CosineSimilarity(dim=1)\n",
        "    train_tensor = torch.tensor(train_embs).to(gpu)\n",
        "    val_tensor = torch.tensor(val_embs).to(gpu)\n",
        "\n",
        "    scores = torch.zeros([val_tensor.shape[0], train_tensor.shape[0]], dtype=torch.float64)\n",
        "    sorted_idx = torch.zeros([val_tensor.shape[0], train_tensor.shape[0]], dtype=torch.int32)\n",
        "\n",
        "    for idx, val_vector in enumerate(tqdm(val_tensor)):\n",
        "        if _score_type == 'pcc':\n",
        "            output = pcc(val_vector.reshape(1, -1), train_tensor)\n",
        "        elif _score_type == 'cos':\n",
        "            output = cos(val_vector.reshape(1, -1), train_tensor)\n",
        "        elif _score_type == 'euclidean':\n",
        "            output = euclidean(val_vector.reshape(1, -1), train_tensor)\n",
        "        index_sorted = torch.argsort(output, descending=True)\n",
        "        scores[idx] = output\n",
        "        sorted_idx[idx] = index_sorted\n",
        "\n",
        "    results = defaultdict(list)\n",
        "\n",
        "    for i, val_id in enumerate(tqdm(val_ids)):\n",
        "        for j, train_idx in enumerate(sorted_idx[i][:1000]):\n",
        "            results[val_id].append((train_ids[train_idx], scores[i][train_idx].item()))\n",
        "\n",
        "    if _submit_type == 'val':\n",
        "        np.save(default_file_path+f'/results/val_scores_title_{_score_type}_24000', results)\n",
        "    elif _submit_type == 'test':\n",
        "        np.save(default_file_path+f'/results/test_scores_title_{_score_type}_24000', results)\n",
        "    elif _submit_type == 'local_val':\n",
        "        np.save(default_file_path+f'/results/local_val_scores_title_{_score_type}_24000', results)\n",
        "    else:\n",
        "        np.save(default_file_path+f'/results/test_scores_title_{_score_type}_24000', results)\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "def get_w2v_scores(submit_type):\n",
        "\n",
        "    project_path = \"/gdrive/MyDrive/colab/melon_playlist_continuation/\"\n",
        "    default_file_path = os.path.join(project_path,\"data\")\n",
        "\n",
        "    if submit_type == 'val':\n",
        "        default_file_path = 'res'\n",
        "        question_file_path = 'res/val.json'\n",
        "        train_file_path = 'res/train.json'\n",
        "    elif submit_type == 'test':\n",
        "        # default_file_path = 'res'\n",
        "        val_file_path = os.path.join(default_file_path,'val.json')\n",
        "        question_file_path = os.path.join(default_file_path,'test.json')\n",
        "        train_file_path = os.path.join(default_file_path,'train.json')\n",
        "    elif submit_type == 'local_val':\n",
        "        default_file_path = 'arena_data'\n",
        "        train_file_path = f'{default_file_path}/orig/train.json'\n",
        "        question_file_path = f'{default_file_path}/questions/val.json'\n",
        "        default_file_path = f'{default_file_path}/orig'\n",
        "\n",
        "    genre_file_path = os.path.join(default_file_path,'genre_gn_all.json')\n",
        "\n",
        "    tokenize_input_file_path = default_file_path+f'/models/tokenizer_input_{method}_{vocab_size}_{submit_type}.txt'\n",
        "\n",
        "    if submit_type == 'local_val':\n",
        "        val_file_path = None\n",
        "        test_file_path = None\n",
        "        train = load_json(train_file_path)\n",
        "        question = load_json(question_file_path)\n",
        "    elif submit_type == 'val':\n",
        "        test_file_path = None\n",
        "        val_file_path = question_file_path\n",
        "        train = load_json(train_file_path)\n",
        "        question = load_json(question_file_path)\n",
        "    elif submit_type == 'test':\n",
        "        val_file_path = val_file_path\n",
        "        test_file_path = question_file_path\n",
        "        train = load_json(train_file_path)\n",
        "        val = load_json(val_file_path)\n",
        "        test = load_json(test_file_path)\n",
        "        train = train + val\n",
        "        question = test\n",
        "\n",
        "    plylst_title_tag_emb = W2V_get_plylsts_embeddings(train, question, submit_type)\n",
        "    W2V_save_scores(train, question, plylst_title_tag_emb, 'cos', submit_type)\n",
        "    "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUH2VkRBSmSY"
      },
      "source": [
        "## recommender.py\n",
        "\n",
        "~~~\n",
        ".\n",
        "├── DicGenerator: 학습한 w2v 모델을 활용하여 플레이리스트의 벡터들에 대해서 embedding을 실시하는 함수\n",
        "├── Recommender: 추천 프로세스를 실행하는 함수\n",
        "│   ├── most_similar: Counter 객체에서 가장 유사한 k개의 element를 반환하는함수\n",
        "│   ├── most_similar_emb: 미리 계산한 유사도 기준 top k 개의 playlist와 score를 반환하는 함수\n",
        "│   ├── get_new_song_plylst_dict: 들어오는 플레이리스트에 대해 새 song : playlist dictionary 생성\n",
        ".\n",
        "~~~"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R13XqiaOSa25"
      },
      "source": [
        "## 라이브러리 불러오기\n",
        "import copy\n",
        "import random\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "from collections import defaultdict\n",
        "from arena_util import write_json, load_json, remove_seen, most_popular\n",
        "\n",
        "## 모델 튜닝을 위해 시드 고정\n",
        "random.seed(777)\n",
        "np.random.seed(777)\n",
        "\n",
        "\n",
        "## 빠른 접근을 위한 Dictionary 생성 \n",
        "def DicGenerator(train, x):\n",
        "    # key: song / value: issue_date\n",
        "    song_issue_dic = defaultdict(lambda: '')\n",
        "\n",
        "    for i in range(len(song_meta)):\n",
        "        song_issue_dic[song_meta[i]['id']] = song_meta[i]['issue_date']\n",
        "\n",
        "    # key: song / value: artist_id_basket\n",
        "    song_artist_dic = defaultdict(lambda: [])\n",
        "\n",
        "    for i in range(len(song_meta)):\n",
        "        lt_art_id = song_meta[i]['artist_id_basket']\n",
        "        song_artist_dic[song_meta[i]['id']] = lt_art_id\n",
        "\n",
        "    # key: song / value: playlist\n",
        "    song_plylst_dic = defaultdict(lambda: [])\n",
        "\n",
        "    for i in range(len(train)):\n",
        "        for t_s in train[i]['songs']:\n",
        "            song_plylst_dic[t_s] += [train[i]['id']]\n",
        "\n",
        "    # key: song / value: tag\n",
        "    song_tag_dic = defaultdict(lambda: [])\n",
        "\n",
        "    for i in range(len(train)):\n",
        "        for t_s in train[i]['songs']:\n",
        "            song_tag_dic[t_s] += train[i]['tags']\n",
        "\n",
        "    # key: plylst / value: song\n",
        "    plylst_song_dic = defaultdict(lambda: [])\n",
        "\n",
        "    for i in range(len(train)):\n",
        "        plylst_song_dic[train[i]['id']] += train[i]['songs']\n",
        "\n",
        "    # key: plylst / value: tag\n",
        "    plylst_tag_dic = defaultdict(lambda: [])\n",
        "\n",
        "    for i in range(len(train)):\n",
        "        plylst_tag_dic[train[i]['id']] += train[i]['tags']\n",
        "\n",
        "    # key: tag / value: plylst\n",
        "    tag_plylst_dic = defaultdict(lambda: [])\n",
        "\n",
        "    for i in range(len(train)):\n",
        "        for t_q in train[i]['tags']:\n",
        "            tag_plylst_dic[t_q] += [train[i]['id']]\n",
        "\n",
        "    # key: tag / value: song\n",
        "    tag_song_dic = defaultdict(lambda: [])\n",
        "\n",
        "    for i in range(len(train)):\n",
        "        for t_q in train[i]['tags']:\n",
        "            tag_song_dic[t_q] += train[i]['songs']\n",
        "\n",
        "    return song_plylst_dic, song_tag_dic, plylst_song_dic, plylst_tag_dic, tag_plylst_dic, tag_song_dic, song_issue_dic, song_artist_dic\n",
        "\n",
        "\n",
        "## 추천 함수\n",
        "\n",
        "'''\n",
        "input\n",
        " > train: 학습에 사용할 playlist들\n",
        " > questions: 일부가 가려진 question용 playlist들\n",
        " > n_msp, n_mtp, sim_measure: 하이퍼파라미터\n",
        " > song_meta: song의 meta 정보\n",
        " > save: 파일 저장 여부\n",
        "output\n",
        " > questions에 대한 최종 추천 리스트\n",
        "'''\n",
        "\n",
        "\n",
        "def Recommender(train, questions, n_msp, n_mtp, mode, sim_measure, song_meta, freq_song, save=False):\n",
        "    ## 최종 추천리스트\n",
        "    rec_list = []\n",
        "\n",
        "    ## 1단계: 전처리\n",
        "    # 1) 추천 결과가 없거나 모자란 경우를 위해 most_popular 생성\n",
        "    _, song_mp = most_popular(train, \"songs\", 200)\n",
        "    _, tag_mp = most_popular(train, \"tags\", 20)\n",
        "\n",
        "    # 2) 빠른 접근을 위한 Dictionary 생성\n",
        "    # {song_id ,:소속_plylst_id}, {song_id : tag_id}, {plylst_id: song_id}, {plylst_id : tag_id}, {tag_id : plylst_id}, {tag_id : song_id}, {song_id, issue_date}, {song_id : artist_id}\n",
        "    song_plylst_dic, song_tag_dic, plylst_song_dic, plylst_tag_dic, tag_plylst_dic, tag_song_dic, song_issue_dic, song_artist_dic = DicGenerator(\n",
        "        train, song_meta)\n",
        "\n",
        "    # 3) 미리 계산한 플레이리스트 유사도 불러오기\n",
        "    '''\n",
        "    sim_scores: 입력으로 들어온 questions과 train간 유사도 (Autoencoder 기반)\n",
        "    gnr_scores: 입력으로 들어온 questions과 train간 유사도 ([Autoencoder] genre 정보 추가) \n",
        "    : 초기 AE 학습시에는 SongTagDataset으로 해놓고 왜... 그 모델을 가지고 SongTagGenreDataset으로 스코어를 낸거를 활용하지??\n",
        "    title_scores: 입력으로 들어온 questions과 train간 유사도 (Word2vec 기반)\n",
        "    '''\n",
        "    sim_scores = np.load(default_file_path+f'/results/{mode}_scores_bias_{sim_measure}.npy', allow_pickle=True).item()\n",
        "    gnr_scores = np.load(default_file_path+f'/results/{mode}_scores_bias_{sim_measure}_gnr.npy', allow_pickle=True).item()\n",
        "    title_scores = np.load(default_file_path+f'/results/{mode}_scores_title_{sim_measure}_24000.npy', allow_pickle=True).item()\n",
        "\n",
        "    ## 2단계: 함수 정의\n",
        "    # 1) Counter 객체에서 빈도수 기준 topk개 출력\n",
        "    def most_similar(cnt, topk):\n",
        "        cnt_topk = cnt.most_common(topk)\n",
        "        return [k for k, v in cnt_topk]\n",
        "\n",
        "    # 2) 미리 계산한 유사도 기준 topk개의 플레이리스트의 plylsts와 scores 출력\n",
        "    def most_similar_emb(q_id, topk, title=False, genre=False):\n",
        "        # title_scores 기준\n",
        "        if title:\n",
        "            plylsts = [t[0] for t in title_scores[q_id][:topk]]\n",
        "            scores = [t[1] for t in title_scores[q_id][:topk]]\n",
        "        # gnr_scores 기준\n",
        "        elif genre:\n",
        "            plylsts = [t[0] for t in gnr_scores[q_id][:topk]]\n",
        "            scores = [t[1] for t in gnr_scores[q_id][:topk]]\n",
        "        # sim_scores 기준\n",
        "        else:\n",
        "            plylsts = [t[0] for t in sim_scores[q_id][:topk]]\n",
        "            scores = [t[1] for t in sim_scores[q_id][:topk]]\n",
        "        return plylsts, scores\n",
        "\n",
        "    # 들어오는 플레이리스트들에 대해서 새로운 {노래 : 플레이리스트}  dictionary 생성\n",
        "    # 3) new_song_plylst_dict\n",
        "    def get_new_song_plylst_dict(plylst_ms):\n",
        "        new_song_plylst_dict = defaultdict(set)\n",
        "        for plylst in plylst_ms:\n",
        "            for _song in plylst_song_dic[plylst]:\n",
        "                new_song_plylst_dict[_song].add(plylst)\n",
        "        return new_song_plylst_dict\n",
        "\n",
        "    ## 3단계: 입력으로 들어온 questions 플레이리스트에 대해 추천\n",
        "    for q in tqdm(questions):\n",
        "\n",
        "        # 1) question 플레이리스트의 정보\n",
        "        # 수록 song/tag\n",
        "        q_songs = q['songs']\n",
        "        q_tags = q['tags']\n",
        "\n",
        "        # 수록 song/tag와 함께 등장한 song/tag/plylst 빈도 수\n",
        "        song_plylst_C = Counter()\n",
        "        song_tag_C = Counter()\n",
        "        tag_plylst_C = Counter()\n",
        "        tag_song_C = Counter()\n",
        "\n",
        "        # 수록 song/tag가 둘 다 없거나 적을 때\n",
        "        no_songs_tags, few_songs_tags = False, False\n",
        "        if len(q_songs) == 0 and len(q_tags) == 0:\n",
        "            no_songs_tags = True\n",
        "        elif len(q_songs) <= 3:\n",
        "            few_songs_tags = True\n",
        "\n",
        "        # 2) 빈도수 기반 추천을 위해 카운트\n",
        "        # 수록 song에 대해\n",
        "        for q_s in q_songs:\n",
        "            song_plylst_C.update(song_plylst_dic[q_s])\n",
        "            song_tag_C.update(song_tag_dic[q_s])\n",
        "        # 수록 tag에 대해\n",
        "        for q_t in q_tags:\n",
        "            tag_plylst_C.update(tag_plylst_dic[q_t])\n",
        "            tag_song_C.update(tag_song_dic[q_t])\n",
        "            # 수록곡 수로 나눠서 비율로 계산\n",
        "        for i, j in list(song_plylst_C.items()):\n",
        "            if len(plylst_song_dic[i]) > 0:\n",
        "                song_plylst_C[i] = (j / len(plylst_song_dic[i]))\n",
        "\n",
        "        # 3) 유사도 기반 추천을 위해 점수 계산\n",
        "        plylst_song_scores = defaultdict(lambda: 0)\n",
        "        plylst_tag_scores = defaultdict(lambda: 0)\n",
        "\n",
        "        # Case 1: song과 tag가 둘 다 없는 경우\n",
        "        if no_songs_tags:\n",
        "            # plylst_ms / plylst_mt: title_scores 기준 유사한 플레이리스트 n_msp / n_mtp개\n",
        "            plylst_ms, song_scores = most_similar_emb(q['id'], n_msp, title=True)\n",
        "            plylst_mt, tag_scores = most_similar_emb(q['id'], n_mtp, title=True)\n",
        "            plylst_add, add_scores = most_similar_emb(q['id'], n_mtp)\n",
        "\n",
        "        # Case 2: song과 tag가 부족한 경우\n",
        "        elif few_songs_tags:\n",
        "            # plylst_ms / plylst_mt: sim_scores 기준 n_msp개 / title_scores 기준 n_mtp개\n",
        "            plylst_ms, song_scores = most_similar_emb(q['id'], n_msp)\n",
        "            plylst_mt, tag_scores = most_similar_emb(q['id'], n_mtp, title=True)\n",
        "            plylst_add, add_scores = most_similar_emb(q['id'], n_mtp, genre=True)\n",
        "\n",
        "        # Case 3: song과 tag가 충분한 경우\n",
        "        else:\n",
        "            # plylst_ms / plylst_mt: sim_scores 기준 유사한 플레이리스트 n_msp / n_mtp개\n",
        "            plylst_ms, song_scores = most_similar_emb(q['id'], n_msp)\n",
        "            plylst_mt, tag_scores = most_similar_emb(q['id'], n_mtp, genre=True)\n",
        "            plylst_add, add_scores = most_similar_emb(q['id'], n_mtp, title=True)\n",
        "\n",
        "        new_song_plylst_dict = get_new_song_plylst_dict(plylst_ms)\n",
        "\n",
        "        # 3-1. plylst_song_scores 계산\n",
        "        for idx, ms_p in enumerate(plylst_ms):\n",
        "            for song in plylst_song_dic[ms_p]:\n",
        "                song_score = 0\n",
        "                for q_s in q_songs:\n",
        "                    try:\n",
        "                        song_score += len(new_song_plylst_dict[q_s] & new_song_plylst_dict[song]) / len(\n",
        "                            new_song_plylst_dict[q_s])\n",
        "                    except:\n",
        "                        pass\n",
        "                if song in freq_song:\n",
        "                    plylst_song_scores[song] += song_plylst_C[ms_p] * song_score * song_scores[idx] * (n_msp - idx) * 4\n",
        "                else:\n",
        "                    plylst_song_scores[song] += song_plylst_C[ms_p] * song_score * song_scores[idx] * (n_msp - idx)\n",
        "            for tag in plylst_tag_dic[ms_p]:\n",
        "                plylst_tag_scores[tag] += tag_scores[idx] * (n_msp - idx)\n",
        "\n",
        "        # 3-2. plylst_tag_scores 계산\n",
        "        for idx, mt_p in enumerate(plylst_mt):\n",
        "            for tag in plylst_tag_dic[mt_p]:\n",
        "                plylst_tag_scores[tag] += tag_scores[idx] * (n_mtp - idx)\n",
        "            for song in plylst_song_dic[mt_p]:\n",
        "                plylst_song_scores[song] += tag_scores[idx]\n",
        "\n",
        "        # 3-3. plylst_{song/tag}_scores 보정\n",
        "        for idx, mt_p in enumerate(plylst_add):\n",
        "            for tag in plylst_tag_dic[mt_p]:\n",
        "                plylst_tag_scores[tag] += add_scores[idx] * (n_mtp - idx)\n",
        "\n",
        "        # 4) song과 tag 둘 다 없거나 적은 경우 예측해서 채워넣기\n",
        "        if no_songs_tags:\n",
        "            # q_songs 새롭게 채워넣기 (원래는 song가 없지만 title_scores 기준 유사한 플레이리스트로부터 song 예측)\n",
        "            pre_songs = sorted(plylst_song_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "            pre_songs = [scores[0] for scores in pre_songs][:200]\n",
        "            pre_songs = pre_songs + remove_seen(pre_songs, song_mp)\n",
        "            q_songs = pre_songs[:100]\n",
        "\n",
        "            # q_tags 새롭게 채워넣기 (원래는 tag가 없지만 title_scores 기준 유사한 플레이리스트로부터 tag 예측)\n",
        "            pre_tags = sorted(plylst_tag_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "            pre_tags = [scores[0] for scores in pre_tags][:20]\n",
        "            pre_tags = pre_tags + remove_seen(pre_tags, tag_mp)\n",
        "            q_tags = pre_tags[:10]\n",
        "\n",
        "        # 5) questions 플레이리스트에 대해 추천\n",
        "        ## song 추천\n",
        "        # song 있을 때\n",
        "        lt_song_art = []\n",
        "        if len(q_songs) > 0:\n",
        "            plylst_song_scores = sorted(plylst_song_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "            lt_artist = []\n",
        "            for w_song in q_songs:\n",
        "                lt_artist.extend(song_artist_dic[w_song])\n",
        "            counter_artist = Counter(lt_artist)\n",
        "            counter_artist = sorted(counter_artist.items(), key=lambda x: x[1], reverse=True)\n",
        "            if few_songs_tags:\n",
        "                artist = [art[0] for art in counter_artist]\n",
        "            else:\n",
        "                artist = [x[0] for x in counter_artist if x[1] > 1]\n",
        "            cand_ms = [scores[0] for scores in plylst_song_scores][(100 - len(artist)):1000]\n",
        "            for cand in cand_ms:\n",
        "                if artist == []:\n",
        "                    break\n",
        "                if cand in q_songs:\n",
        "                    break\n",
        "                for art in song_artist_dic[cand]:\n",
        "                    if art in artist:\n",
        "                        lt_song_art.append(cand)\n",
        "                        artist.remove(art)\n",
        "                        break\n",
        "            song_ms = [scores[0] for scores in plylst_song_scores][:200]\n",
        "\n",
        "\n",
        "        # song 없고, tag 있을 때\n",
        "        else:\n",
        "            song_ms = most_similar(tag_song_C, 200)\n",
        "\n",
        "        ## tag 추천\n",
        "        # tag 있을 때\n",
        "        if len(q_tags) > 0:\n",
        "            plylst_tag_scores = sorted(plylst_tag_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "            tag_ms = [scores[0] for scores in plylst_tag_scores][:20]\n",
        "\n",
        "        # tag 없고, song 있을 때\n",
        "        else:\n",
        "            plylst_tag_scores = sorted(plylst_tag_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "            tag_ms = [scores[0] for scores in plylst_tag_scores][:20]\n",
        "\n",
        "        ## issue date 늦은 song 제거\n",
        "        if q['updt_date']:\n",
        "            q_updt_date = q['updt_date'][:4] + q['updt_date'][5:7] + q['updt_date'][8:10]\n",
        "            song_ms = [x for x in song_ms if song_issue_dic[x] < q_updt_date]\n",
        "\n",
        "        ## 중복 제거 및 부족하면 most_popular로 채워넣기\n",
        "        song_candidate = song_ms + remove_seen(song_ms, song_mp)\n",
        "        tag_candidate = tag_ms + remove_seen(tag_ms, tag_mp)\n",
        "\n",
        "        song_remove = q_songs\n",
        "        tag_remove = q_tags\n",
        "\n",
        "        song_candidate = song_candidate[:100] if no_songs_tags else remove_seen(song_remove, song_candidate)[:100]\n",
        "        if len(lt_song_art) > 0:\n",
        "            lt_song_art = [x for x in lt_song_art if x not in song_candidate]\n",
        "            song_candidate[(100 - len(lt_song_art)):100] = lt_song_art\n",
        "\n",
        "        rec_list.append({\n",
        "            \"id\": q[\"id\"],\n",
        "            \"songs\": song_candidate,\n",
        "            \"tags\": tag_candidate[:10] if no_songs_tags else remove_seen(tag_remove, tag_candidate)[:10]\n",
        "        })\n",
        "\n",
        "    # 6) results.json 파일 저장 여부\n",
        "    if save == True:\n",
        "        write_json(rec_list, 'results/results_' + dt.datetime.now().strftime(\"%y%m%d-%H%M%S\") + '_' + mode + '.json')\n",
        "\n",
        "    return rec_list"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yaltgjGRwET"
      },
      "source": [
        "## Inference.py\n",
        "\n",
        "학습된 모델을 가지고 추천을 수행하는 python script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQSHjGBy_EgT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5cf8851-15e1-4a5e-d273-55473bfd2a13"
      },
      "source": [
        "import sys\n",
        "# from MelonDataset import SongTagDataset, SongTagGenreDataset\n",
        "from arena_util import write_json, load_json\n",
        "# from get_autoencoder_scores import get_autoencoder_scores\n",
        "# from get_w2v_scores import get_w2v_scores\n",
        "# import argparse\n",
        "# from recommender import Recommender\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# 유사도 측정 방식\n",
        "sim_measure = 'cos'\n",
        "\n",
        "# 상위 song / tag 추출 개수\n",
        "n_msp = 50\n",
        "n_mtp = 90\n",
        "freq_thr = 2\n",
        "\n",
        "mode = 2\n",
        "_submit_type = mode\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     parser = argparse.ArgumentParser()\n",
        "#     parser.add_argument('-mode', type=int, help=\"local_val: 0, val: 1, test: 2\", default=2)\n",
        "#     args = parser.parse_args()\n",
        "#     _submit_type = args.mode\n",
        "\n",
        "if _submit_type == 0:  # split data에 대해서는 훈련 중간 중간 성능 확인을 위해서 question, answer 불러옴\n",
        "    default_file_path = 'arena_data/'\n",
        "    model_postfix = 'local_val'\n",
        "\n",
        "    train_file_path = f'{default_file_path}/orig/train.json'\n",
        "    question_file_path = f'{default_file_path}/questions/val.json'\n",
        "    answer_file_path = f'{default_file_path}/answers/val.json'\n",
        "\n",
        "    train_data = load_json(train_file_path)\n",
        "    question_data = load_json(question_file_path)\n",
        "    model_file_path = \"model/autoencoder_450_256_0.0005_0.2_2_local_val.pkl\"\n",
        "    auto_score_file_path = \"scores/local_val_scores_bias_cos\"\n",
        "    w2v_score_file_path = 'scores/local_val_scores_title_cos_24000'\n",
        "\n",
        "elif _submit_type == 1:\n",
        "    default_file_path = 'res'\n",
        "    model_postfix = 'val'\n",
        "\n",
        "    train_file_path = f'{default_file_path}/train.json'\n",
        "    val_file_path = f'{default_file_path}/val.json'\n",
        "    train_data = load_json(train_file_path) + load_json(val_file_path)\n",
        "    question_data = load_json(val_file_path)\n",
        "    model_file_path = \"model/autoencoder_450_256_0.0005_0.2_2_val.pkl\"\n",
        "    auto_score_file_path = \"scores/val_scores_bias_cos\"\n",
        "    w2v_score_file_path = 'scores/val_scores_title_cos_24000'\n",
        "\n",
        "elif _submit_type == 2:\n",
        "    # default_file_path = 'res'\n",
        "    model_postfix = 'test'\n",
        "\n",
        "    train_file_path = f'{default_file_path}/train.json'\n",
        "    val_file_path = f'{default_file_path}/val.json'\n",
        "    test_file_path = f'{default_file_path}/test.json'\n",
        "    train_data = load_json(train_file_path) + load_json(val_file_path) + load_json(val_file_path) + load_json(\n",
        "        test_file_path)\n",
        "    question_data = load_json(test_file_path)\n",
        "    model_file_path = default_file_path+\"/models/autoencoder_450_256_0.0005_0.2_2_test.pkl\"\n",
        "    auto_score_file_path = default_file_path+\"/results/test_scores_bias_cos\"\n",
        "    w2v_score_file_path = default_file_path+'/results/test_scores_title_cos_24000'\n",
        "\n",
        "else:\n",
        "    print('mode error! local_val: 0, val: 1, test: 2')\n",
        "    sys.exit(1)\n",
        "\n",
        "# Autoencoder의 input: song, tag binary vector의 concatenate, tags는 str이므로 id로 변형할 필요 있음\n",
        "tag2id_file_path = f'{default_file_path}/tag2id_{model_postfix}.npy'\n",
        "id2tag_file_path = f'{default_file_path}/id2tag_{model_postfix}.npy'\n",
        "# Song이 너무 많기 때문에 frequency에 기반하여 freq_thr번 이상 등장한 곡들만 남김, 남은 곡들에게 새로운 id 부여\n",
        "prep_song2id_file_path = f'{default_file_path}/freq_song2id_thr{freq_thr}_{model_postfix}.npy'\n",
        "id2prep_song_file_path = f'{default_file_path}/id2freq_song_thr{freq_thr}_{model_postfix}.npy'\n",
        "\n",
        "tokenizer_model_path = default_file_path+'/models/tokenizer_bpe_24000_{}.model'.format(model_postfix)\n",
        "w2v_model_path = default_file_path+'/models/w2v_bpe_24000_{}.model'.format(model_postfix)\n",
        "if (not os.path.exists(model_file_path)) or (not os.path.exists(tokenizer_model_path)) \\\n",
        "        or (not os.path.exists(w2v_model_path)):\n",
        "    print(\"Error: there is no autoencoder model. Please execute train.py first\")\n",
        "    sys.exit(1)\n",
        "\n",
        "if (not os.path.exists(auto_score_file_path + '.npy')) or (not os.path.exists(auto_score_file_path + '_gnr.npy')):\n",
        "    get_autoencoder_scores(model_file_path, model_postfix)\n",
        "if not os.path.exists(w2v_score_file_path + '.npy'):\n",
        "    get_w2v_scores(model_postfix)\n",
        "\n",
        "# song_meta = load_json(os.path.join(default_file_path,'song_meta.json'))\n",
        "# prep_song2id = dict(np.load(prep_song2id_file_path, allow_pickle=True).item())\n",
        "# freq_song = set(prep_song2id.keys())\n",
        "\n",
        "# rec_list = Recommender(train_data, question_data, n_msp, n_mtp, model_postfix, sim_measure, song_meta, freq_song,\n",
        "#                         save=True)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "saving embeddings\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 138086/138086 [00:13<00:00, 10563.37it/s]\n",
            "100%|██████████| 10740/10740 [00:00<00:00, 16143.29it/s]\n",
            "  2%|▏         | 3178/148826 [00:00<00:04, 31768.59it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "saving scores...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 148826/148826 [04:38<00:00, 533.70it/s]\n",
            "100%|██████████| 10740/10740 [00:38<00:00, 281.47it/s]\n",
            "100%|██████████| 10740/10740 [01:34<00:00, 114.14it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8Qb3UxQBXO9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}